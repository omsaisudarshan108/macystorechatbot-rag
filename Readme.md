ğŸ›’ Retail Knowledge RAG Platform

An enterprise-grade Retail Intelligence System built using Retrieval-Augmented Generation (RAG) with:

Hybrid Search â€“ Chroma (vector) + BM25 (lexical)

Reranking â€“ Cross-Encoder

LLM â€“ Google Vertex AI Gemini

Backend â€“ FastAPI

Frontend â€“ Streamlit

Persistent Storage â€“ Chroma PersistentClient + BM25 pickle

Evidence-Backed Answers â€“ Citations + Snippets

Evaluation Ready â€“ RAGAS compatible

ğŸ“ Architecture
Streamlit UI  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  FastAPI Backend  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  Vertex AI Gemini
     â”‚                           â”‚
     â”‚                           â”‚
     â–¼                           â–¼
File Uploads                Hybrid Retrieval
                           â”œâ”€â”€ Chroma Vector DB (Persistent)
                           â”œâ”€â”€ BM25 Lexical Index (Pickled)
                           â”œâ”€â”€ Cross-Encoder Reranker
                           â””â”€â”€ Citation Generator

ğŸ“ Folder Structure
Rag_Retail_App/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ loaders.py
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â””â”€â”€ embedders.py
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ chroma_vectorstore.py
â”‚   â”‚   â”œâ”€â”€ bm25_store.py
â”‚   â”‚   â”œâ”€â”€ hybrid.py
â”‚   â”‚   â””â”€â”€ reranker.py
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ vertex.py
â”‚   â””â”€â”€ eval/
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ run_ragas.py
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma/        # Vector DB persistence
â”‚   â”œâ”€â”€ raw/           # Uploaded files
â”‚   â””â”€â”€ bm25.pkl       # BM25 index
â”‚
â””â”€â”€ README.md

ğŸ” Prerequisites

Python 3.10+

Google Cloud SDK installed

Vertex AI enabled in your GCP project

Authenticate once:

gcloud auth application-default login

ğŸ“¦ Installation
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

â–¶ Running the Platform
1ï¸âƒ£ Start FastAPI Backend
uvicorn backend.api.main:app --reload --host 0.0.0.0 --port 8000


Verify:

http://127.0.0.1:8000/docs

2ï¸âƒ£ Start Streamlit UI (new terminal)
streamlit run ui/app.py


Open:

http://localhost:8501

ğŸ“¤ Upload Knowledge Base Files

Select Store ID.

Upload one or more files (PDF, DOCX, TXT).

Click Ingest Files.

During ingestion:

Files are chunked semantically.

Chunks are embedded.

Stored in Chroma.

Indexed in BM25.

Persisted to disk.

â“ Ask Questions

Enter retail support or operational questions.

Example:

Why is kiosk showing incorrect store information?


Answers are returned with citations and supporting snippets.

ğŸ’¾ Persistence Model
Component	Location
Chroma Vector DB	data/chroma/
BM25 Index	data/bm25.pkl
Uploaded Files	data/raw/

Indexes survive FastAPI restarts.

ğŸ“Š RAG Evaluation (RAGAS)

After collecting real usage:

python backend/eval/run_ragas.py


Metrics generated:

Faithfulness

Answer Relevancy

Context Precision

Context Recall

ğŸ›¡ Production Capabilities
Feature	Status
Hybrid Retrieval	âœ…
Semantic Chunking	âœ…
Cross-Encoder Reranking	âœ…
Vertex AI Gemini	âœ…
Persistent Indexes	âœ…
Evidence Citations	âœ…
Multi-file Upload	âœ…
RAG Evaluation	âœ…
ğŸ Result

This platform is a production-grade retail knowledge system designed for store operations, incident resolution, SOP discovery, and analytics â€” not a demo chatbot.